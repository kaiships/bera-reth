# Runs hive compatibility tests for bera-reth
# Tests multiple simulators in parallel and compares results to reth:nightly

name: hive

on:
  workflow_dispatch:
  schedule:
    # Run 5 hours after nightly builds (1 AM + 5 hours = 6 AM, 1 PM + 5 hours = 6 PM UTC)
    - cron: "0 6,18 * * *"

env:
  CARGO_TERM_COLOR: always

permissions:
  issues: write
  contents: read

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

jobs:
  prepare-hive:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    outputs:
      simulators: ${{ steps.build-simulators.outputs.simulators }}
    steps:
      - uses: actions/checkout@v5

      - name: Checkout hive tests
        uses: actions/checkout@v5
        with:
          repository: berachain/hive
          ref: master
          path: hivetests

      - uses: actions/setup-go@v5
        with:
          go-version: "^1.21"

      - name: Build hive binary and cache simulators
        id: build-simulators
        run: |
          cd hivetests
          go build .
          
          # Build all simulator images we'll need
          echo "Building RPC compatibility simulator"
          ./hive --sim "ethereum/rpc-compat" --sim.timelimit 1s || true
          
          echo "Building sync simulator" 
          ./hive --sim "ethereum/sync" --sim.timelimit 1s || true
          
          # Create list of built simulators for matrix
          echo "simulators=[\"ethereum/rpc-compat\", \"ethereum/sync\"]" >> $GITHUB_OUTPUT

      - name: Save hive workspace
        run: |
          mkdir -p /tmp/hive-assets
          tar -czf /tmp/hive-assets/hive-binary.tar.gz -C hivetests .

      - name: Upload hive assets
        uses: actions/upload-artifact@v4
        with:
          name: hive-assets
          path: /tmp/hive-assets

  test:
    needs: prepare-hive
    timeout-minutes: 90
    strategy:
      fail-fast: false
      matrix:
        scenario:
          - sim: ethereum/rpc-compat
            name: rpc-compat
            use_comparison: true
          - sim: ethereum/sync
            name: sync
            use_comparison: false
    name: hive ${{ matrix.scenario.name }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v5

      - name: Download hive assets
        uses: actions/download-artifact@v4
        with:
          name: hive-assets
          path: /tmp/hive-assets

      - name: Extract hive workspace
        run: |
          mkdir -p hivetests
          tar -xzf /tmp/hive-assets/hive-binary.tar.gz -C hivetests

      - name: Run ${{ matrix.scenario.sim }} tests for both clients
        run: |
          cd hivetests
          echo "Running ${{ matrix.scenario.sim }} tests for bera-reth and reth:nightly"
          # Test both clients in a single run for direct comparison
          ./hive --sim ${{ matrix.scenario.sim }} --client bera-reth,reth
        continue-on-error: true

      - name: Save test results
        run: |
          mkdir -p /tmp/results
          cp -r hivetests/workspace/logs /tmp/results/hive-logs

      - name: Upload test results
        uses: actions/upload-artifact@v4
        with:
          name: hive-results-${{ matrix.scenario.name }}
          path: /tmp/results/hive-logs

      - name: Analyze test results
        run: |
          RESULTS_JSON=$(find /tmp/results/hive-logs -name "*-*.json" | sort | tail -1)
          
          if [[ "${{ matrix.scenario.use_comparison }}" == "true" ]]; then
            # Use comparison script to compare failure patterns
            set +e  # Allow script to exit with non-zero (we handle it below)
            ./scripts/compare-hive-results.sh /tmp/results/hive-logs > /tmp/comparison_output.txt 2>&1
            COMPARISON_EXIT_CODE=$?
            set -e
            
            echo "=== HIVE ${{ matrix.scenario.name }} COMPATIBILITY COMPARISON ==="
            cat /tmp/comparison_output.txt
            
            # Create markdown report from script output
            echo "## Hive ${{ matrix.scenario.name }} Compatibility Test Results" > /tmp/report.md
            echo "" >> /tmp/report.md
            echo "**Run Date:** $(date -u)" >> /tmp/report.md
            echo "**Simulator:** ${{ matrix.scenario.sim }}" >> /tmp/report.md
            echo "" >> /tmp/report.md
            echo '```' >> /tmp/report.md
            cat /tmp/comparison_output.txt >> /tmp/report.md
            echo '```' >> /tmp/report.md
            
            if [[ $COMPARISON_EXIT_CODE -eq 0 ]]; then
              echo "TEST_STATUS=success" >> $GITHUB_ENV
            else
              echo "TEST_STATUS=failure" >> $GITHUB_ENV
            fi
          else
            # Simple pass/fail based on test results
            TOTAL_TESTS=$(jq '[.testCases[]] | length' "$RESULTS_JSON")
            FAILED_TESTS=$(jq '[.testCases[] | select(.summaryResult.pass == false)] | length' "$RESULTS_JSON")
            PASSED_TESTS=$((TOTAL_TESTS - FAILED_TESTS))
            
            echo "=== HIVE ${{ matrix.scenario.name }} TEST RESULTS ==="
            echo "Total tests: $TOTAL_TESTS"
            echo "Passed: $PASSED_TESTS"
            echo "Failed: $FAILED_TESTS"
            
            # Create markdown report
            echo "## Hive ${{ matrix.scenario.name }} Test Results" > /tmp/report.md
            echo "" >> /tmp/report.md
            echo "**Run Date:** $(date -u)" >> /tmp/report.md
            echo "**Simulator:** ${{ matrix.scenario.sim }}" >> /tmp/report.md
            echo "" >> /tmp/report.md
            echo "- **Total tests**: $TOTAL_TESTS" >> /tmp/report.md
            echo "- **Passed**: $PASSED_TESTS" >> /tmp/report.md
            echo "- **Failed**: $FAILED_TESTS" >> /tmp/report.md
            
            if [[ $FAILED_TESTS -eq 0 ]]; then
              echo "TEST_STATUS=success" >> $GITHUB_ENV
              echo "" >> /tmp/report.md
              echo "✅ All tests passed!" >> /tmp/report.md
            else
              echo "TEST_STATUS=failure" >> $GITHUB_ENV
              echo "" >> /tmp/report.md
              echo "❌ $FAILED_TESTS tests failed" >> /tmp/report.md
              
              # List failed tests
              echo "" >> /tmp/report.md
              echo "### Failed Tests" >> /tmp/report.md
              jq -r '.testCases[] | select(.summaryResult.pass == false) | "- " + .name' "$RESULTS_JSON" >> /tmp/report.md
            fi
          fi
          
          # Add common footer
          echo "" >> /tmp/report.md
          echo "### Artifacts" >> /tmp/report.md
          echo "- Test logs: Available as 'hive-results-${{ matrix.scenario.name }}' artifact" >> /tmp/report.md
          echo "" >> /tmp/report.md
          echo "### Workflow Run" >> /tmp/report.md
          echo "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}" >> /tmp/report.md

      - name: Upload comparison report
        uses: actions/upload-artifact@v4
        with:
          name: comparison-report-${{ matrix.scenario.name }}
          path: /tmp/report.md

      - name: Create issue on regression
        if: env.TEST_STATUS == 'failure'
        uses: actions/github-script@v6
        with:
          script: |
            const date = new Date().toISOString().split('T')[0];
            const workflowUrl = `${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}`;
            const simulator = '${{ matrix.scenario.sim }}';
            const name = '${{ matrix.scenario.name }}';
            
            const useComparison = '${{ matrix.scenario.use_comparison }}' === 'true';
            const issueType = useComparison ? 'regression' : 'failure';
            const issueBody = useComparison ? 
              `## Hive ${name} Compatibility Regression
            
            **Date:** ${date}
            **Simulator:** ${simulator}
            **Workflow Run:** ${workflowUrl}
            
            ### Issue
            Automated hive tests detected that bera-reth fails different individual tests than reth:nightly. This indicates a regression or behavioral difference that needs investigation.
            
            ### Next Steps
            1. Review the [workflow run details](${workflowUrl}) for specific test differences
            2. Check which tests are failing only in bera-reth vs reth:nightly
            3. Investigate the root cause of the behavioral differences
            4. Fix the regression or update tests if the change is intentional
            
            ### Test Commands
            To reproduce locally:
            \`\`\`bash
            hive --sim ${simulator} --client bera-reth,reth
            \`\`\`
            
            This issue was automatically created by the hive workflow.` :
              `## Hive ${name} Test Failure
            
            **Date:** ${date}
            **Simulator:** ${simulator}
            **Workflow Run:** ${workflowUrl}
            
            ### Issue
            Automated hive ${name} tests are failing. This indicates a problem with bera-reth functionality that needs investigation.
            
            ### Next Steps
            1. Review the [workflow run details](${workflowUrl}) for specific test failures
            2. Check the test logs for error details
            3. Investigate and fix the failing functionality
            
            ### Test Commands
            To reproduce locally:
            \`\`\`bash
            hive --sim ${simulator} --client bera-reth,reth
            \`\`\`
            
            This issue was automatically created by the hive workflow.`;

            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `fix: hive ${name} ${issueType} detected - ${date}`,
              body: issueBody,
              labels: ['hive', 'regression']
            });

      - name: Fail job on regression
        if: env.TEST_STATUS == 'failure'
        run: |
          if [[ "${{ matrix.scenario.use_comparison }}" == "true" ]]; then
            echo "❌ bera-reth fails different ${{ matrix.scenario.name }} tests than reth:nightly"
            echo "GitHub issue created for tracking this regression"
          else
            echo "❌ bera-reth ${{ matrix.scenario.name }} tests failed"
            echo "GitHub issue created for tracking this failure"
          fi
          exit 1